# Sampling Iceberg tables.
select * from functional_parquet.iceberg_non_partitioned tablesample system(10) repeatable(1234)
---- PLAN
F00:PLAN FRAGMENT [UNPARTITIONED] hosts=1 instances=1
|  Per-Host Resources: mem-estimate=68.00MB mem-reservation=4.03MB thread-reservation=2
PLAN-ROOT SINK
|  output exprs: functional_parquet.iceberg_non_partitioned.id, functional_parquet.iceberg_non_partitioned.user, functional_parquet.iceberg_non_partitioned.action, functional_parquet.iceberg_non_partitioned.event_time
|  mem-estimate=4.00MB mem-reservation=4.00MB spill-buffer=2.00MB thread-reservation=0
|
00:SCAN HDFS [functional_parquet.iceberg_non_partitioned]
   HDFS partitions=1/1 files=3 size=3.41KB
   Iceberg snapshot id: 93996984692289973
   stored statistics:
     table: rows=20 size=22.90KB
     columns: unavailable
   extrapolated-rows=unavailable max-scan-range-rows=6
   mem-estimate=64.00MB mem-reservation=32.00KB thread-reservation=1
   tuple-ids=0 row-size=44B cardinality=3
   in pipelines: 00(GETNEXT)
====
# Sampling Iceberg tables. Count(*) is optimized.
select count(*) from functional_parquet.iceberg_non_partitioned tablesample system(10) repeatable(1234)
---- PLAN
F00:PLAN FRAGMENT [UNPARTITIONED] hosts=1 instances=1
|  Per-Host Resources: mem-estimate=1.02MB mem-reservation=8.00KB thread-reservation=2
PLAN-ROOT SINK
|  output exprs: count(*)
|  mem-estimate=0B mem-reservation=0B thread-reservation=0
|
01:AGGREGATE [FINALIZE]
|  output: sum_init_zero(functional_parquet.iceberg_non_partitioned.stats: num_rows)
|  mem-estimate=16.00KB mem-reservation=0B spill-buffer=2.00MB thread-reservation=0
|  tuple-ids=1 row-size=8B cardinality=1
|  in pipelines: 01(GETNEXT), 00(OPEN)
|
00:SCAN HDFS [functional_parquet.iceberg_non_partitioned]
   HDFS partitions=1/1 files=3 size=3.41KB
   Iceberg snapshot id: 93996984692289973
   stored statistics:
     table: rows=20 size=22.90KB
     columns: all
   extrapolated-rows=unavailable max-scan-range-rows=6
   mem-estimate=1.00MB mem-reservation=8.00KB thread-reservation=1
   tuple-ids=0 row-size=8B cardinality=20
   in pipelines: 00(GETNEXT)
====
# Sampling partitioned Iceberg tables.
select * from functional_parquet.iceberg_partitioned tablesample system(50) repeatable(1234)
---- PLAN
F00:PLAN FRAGMENT [UNPARTITIONED] hosts=1 instances=1
|  Per-Host Resources: mem-estimate=68.00MB mem-reservation=4.03MB thread-reservation=2
PLAN-ROOT SINK
|  output exprs: functional_parquet.iceberg_partitioned.id, functional_parquet.iceberg_partitioned.user, functional_parquet.iceberg_partitioned.action, functional_parquet.iceberg_partitioned.event_time
|  mem-estimate=4.00MB mem-reservation=4.00MB spill-buffer=2.00MB thread-reservation=0
|
00:SCAN HDFS [functional_parquet.iceberg_partitioned]
   HDFS partitions=3/3 files=10 size=11.46KB
   Iceberg snapshot id: 8270633197658268308
   stored statistics:
     table: rows=20 size=22.90KB
     columns: unavailable
   extrapolated-rows=unavailable max-scan-range-rows=2
   mem-estimate=64.00MB mem-reservation=32.00KB thread-reservation=1
   tuple-ids=0 row-size=44B cardinality=10
   in pipelines: 00(GETNEXT)
====
# Sampling Iceberg tables with predicates. Predicate pushdown to Iceberg happens
# before sampling (similarly to static partition pruning).
select * from functional_parquet.iceberg_partitioned tablesample system(50) repeatable(1234)
where action = 'click' and id > 0
---- PLAN
F00:PLAN FRAGMENT [UNPARTITIONED] hosts=1 instances=1
|  Per-Host Resources: mem-estimate=68.00MB mem-reservation=4.03MB thread-reservation=2
PLAN-ROOT SINK
|  output exprs: functional_parquet.iceberg_partitioned.id, functional_parquet.iceberg_partitioned.user, functional_parquet.iceberg_partitioned.action, functional_parquet.iceberg_partitioned.event_time
|  mem-estimate=4.00MB mem-reservation=4.00MB spill-buffer=2.00MB thread-reservation=0
|
00:SCAN HDFS [functional_parquet.iceberg_partitioned]
   HDFS partitions=1/3 files=4 size=4.57KB
   predicates: id > CAST(0 AS INT)
   Iceberg snapshot id: 8270633197658268308
   skipped Iceberg predicates: action = 'click'
   stored statistics:
     table: rows=20 size=22.90KB
     columns: unavailable
   extrapolated-rows=unavailable max-scan-range-rows=5
   parquet statistics predicates: id > CAST(0 AS INT)
   parquet dictionary predicates: id > CAST(0 AS INT)
   mem-estimate=64.00MB mem-reservation=32.00KB thread-reservation=1
   tuple-ids=0 row-size=44B cardinality=1
   in pipelines: 00(GETNEXT)
====
# Sampling Iceberg V2 tables. Delete files are not sampled, only the data files. So we
# don't return rows that are deleted.
select * from functional_parquet.iceberg_v2_positional_not_all_data_files_have_delete_files
tablesample system(10) repeatable(1234)
---- PLAN
F00:PLAN FRAGMENT [UNPARTITIONED] hosts=1 instances=1
|  Per-Host Resources: mem-estimate=100.00MB mem-reservation=4.05MB thread-reservation=3
PLAN-ROOT SINK
|  output exprs: functional_parquet.iceberg_v2_positional_not_all_data_files_have_delete_files.i, functional_parquet.iceberg_v2_positional_not_all_data_files_have_delete_files.s
|  mem-estimate=4.00MB mem-reservation=4.00MB spill-buffer=2.00MB thread-reservation=0
|
04:UNION
|  pass-through-operands: all
|  mem-estimate=0B mem-reservation=0B thread-reservation=0
|  tuple-ids=0 row-size=36B cardinality=4
|  in pipelines: 03(GETNEXT), 00(GETNEXT)
|
|--02:DELETE EVENTS ICEBERG DELETE [ICEBERG DELETE JOIN]
|  |  equality predicates: functional_parquet.iceberg_v2_positional_not_all_data_files_have_delete_files.file__position = functional_parquet.iceberg_v2_positional_not_all_data_files_have_delete_files-position-delete.pos, functional_parquet.iceberg_v2_positional_not_all_data_files_have_delete_files.input__file__name = functional_parquet.iceberg_v2_positional_not_all_data_files_have_delete_files-position-delete.file_path
|  |  mem-estimate=566B mem-reservation=566B thread-reservation=0
|  |  tuple-ids=0 row-size=36B cardinality=3
|  |  in pipelines: 00(GETNEXT), 01(OPEN)
|  |
|  |--01:SCAN HDFS [functional_parquet.iceberg_v2_positional_not_all_data_files_have_delete_files-POSITION-DELETE-01 functional_parquet.iceberg_v2_positional_not_all_data_files_have_delete_files-position-delete]
|  |     HDFS partitions=1/1 files=2 size=5.33KB
|  |     Iceberg snapshot id: 1497619269847778439
|  |     stored statistics:
|  |       table: rows=4 size=5.33KB
|  |       columns: all
|  |     extrapolated-rows=unavailable max-scan-range-rows=2
|  |     mem-estimate=32.00MB mem-reservation=16.00KB thread-reservation=1
|  |     tuple-ids=1 row-size=267B cardinality=4
|  |     in pipelines: 01(GETNEXT)
|  |
|  00:SCAN HDFS [functional_parquet.iceberg_v2_positional_not_all_data_files_have_delete_files]
|     HDFS partitions=1/1 files=1 size=625B
|     Iceberg snapshot id: 1497619269847778439
|     stored statistics:
|       table: rows=10 size=7.77KB
|       columns missing stats: i, s
|     extrapolated-rows=unavailable max-scan-range-rows=10
|     mem-estimate=64.00MB mem-reservation=32.00KB thread-reservation=1
|     tuple-ids=0 row-size=36B cardinality=3
|     in pipelines: 00(GETNEXT)
|
03:SCAN HDFS [functional_parquet.iceberg_v2_positional_not_all_data_files_have_delete_files]
   HDFS partitions=1/1 files=1 size=620B
   Iceberg snapshot id: 1497619269847778439
   stored statistics:
     table: rows=10 size=7.77KB
     columns missing stats: i, s
   extrapolated-rows=unavailable max-scan-range-rows=10
   mem-estimate=64.00MB mem-reservation=32.00KB thread-reservation=1
   tuple-ids=0 row-size=36B cardinality=1
   in pipelines: 03(GETNEXT)
====
# Cardinality of DELETE EVENTS ICEBERG DELETE should take the sampling percentage into account.
# Delete records cardinality: 3
# Sampling percentage: 35%
# Effective delete records count: 3 * 0.35 = 1
# DELETE EVENTS ICEBERG DELETE cardinality = 3 (Left SCAN node cardinality) - 1 (Effective delete records count) = 2
select * from functional_parquet.iceberg_v2_positional_update_all_rows tablesample system(35) repeatable(1234);
---- PLAN
F00:PLAN FRAGMENT [UNPARTITIONED] hosts=1 instances=1
|  Per-Host Resources: mem-estimate=100.00MB mem-reservation=4.05MB thread-reservation=3
PLAN-ROOT SINK
|  output exprs: functional_parquet.iceberg_v2_positional_update_all_rows.i, functional_parquet.iceberg_v2_positional_update_all_rows.s
|  mem-estimate=4.00MB mem-reservation=4.00MB spill-buffer=2.00MB thread-reservation=0
|
04:UNION
|  pass-through-operands: all
|  mem-estimate=0B mem-reservation=0B thread-reservation=0
|  tuple-ids=0 row-size=36B cardinality=5
|  in pipelines: 03(GETNEXT), 00(GETNEXT)
|
|--02:DELETE EVENTS ICEBERG DELETE [ICEBERG DELETE JOIN]
|  |  equality predicates: functional_parquet.iceberg_v2_positional_update_all_rows.file__position = functional_parquet.iceberg_v2_positional_update_all_rows-position-delete.pos, functional_parquet.iceberg_v2_positional_update_all_rows.input__file__name = functional_parquet.iceberg_v2_positional_update_all_rows-position-delete.file_path
|  |  mem-estimate=764B mem-reservation=764B thread-reservation=0
|  |  tuple-ids=0 row-size=36B cardinality=2
|  |  in pipelines: 00(GETNEXT), 01(OPEN)
|  |
|  |--01:SCAN HDFS [functional_parquet.iceberg_v2_positional_update_all_rows-POSITION-DELETE-01 functional_parquet.iceberg_v2_positional_update_all_rows-position-delete]
|  |     HDFS partitions=1/1 files=1 size=2.60KB
|  |     Iceberg snapshot id: 3877007445826010687
|  |     stored statistics:
|  |       table: rows=3 size=2.60KB
|  |       columns: all
|  |     extrapolated-rows=disabled max-scan-range-rows=3
|  |     mem-estimate=32.00MB mem-reservation=16.00KB thread-reservation=1
|  |     tuple-ids=1 row-size=246B cardinality=3
|  |     in pipelines: 01(GETNEXT)
|  |
|  00:SCAN HDFS [functional_parquet.iceberg_v2_positional_update_all_rows]
|     HDFS partitions=1/1 files=1 size=625B
|     Iceberg snapshot id: 3877007445826010687
|     stored statistics:
|       table: rows=6 size=3.82KB
|       columns missing stats: i, s
|     extrapolated-rows=disabled max-scan-range-rows=6
|     mem-estimate=64.00MB mem-reservation=32.00KB thread-reservation=1
|     tuple-ids=0 row-size=36B cardinality=3
|     in pipelines: 00(GETNEXT)
|
03:SCAN HDFS [functional_parquet.iceberg_v2_positional_update_all_rows]
   HDFS partitions=1/1 files=1 size=625B
   Iceberg snapshot id: 3877007445826010687
   stored statistics:
     table: rows=6 size=3.82KB
     columns missing stats: i, s
   extrapolated-rows=disabled max-scan-range-rows=6
   mem-estimate=64.00MB mem-reservation=32.00KB thread-reservation=1
   tuple-ids=0 row-size=36B cardinality=3
   in pipelines: 03(GETNEXT)
====
